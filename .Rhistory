preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
predict(preg_wf, new_data=biketest)
submission <- bike_predictions %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=1, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=1, mixture=1) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=.025, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=0, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=0.05, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=0.5, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
preg_model <- linear_reg(penalty=100, mixture=0) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model) %>%
fit(data=biketrain)
bike_predictions_pen <- predict(preg_wf, new_data=biketest)
submission <- bike_predictions_pen %>%
mutate(datetime = biketest$datetime) %>%
mutate(datetime=as.character(format(datetime)))  %>%
mutate(count = exp(.pred)) %>% #transform back to original scale
select(2, 3)
vroom_write(submission, "submissionpenalized.csv", delim = ",")
?rbinom
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod <- logistic_reg(mixture=, penalty=) %>% #Type of model
set_engine("glmnet")
###########################################################
#Logistic Regression
###########################################################
library(tidymodels)
amazontrain <- vroom("./train.csv")
amazontest <- vroom("./test.csv")
library(vroom)
amazontrain <- vroom("./train.csv")
amazontest <- vroom("./test.csv")
amazontrain <- amazontrain %>%
mutate(ACTION = as.factor(ACTION))
amazontrain <- amazontrain %>%
mutate(ACTION = as.factor(ACTION))
library(tidyverse)
library(tidymodels)
library(vroom)
library(embed)
amazontrain <- vroom("./train.csv")
amazontest <- vroom("./test.csv")
amazontrain <- amazontrain %>%
mutate(ACTION = as.factor(ACTION))
setwd("~/Braden/Uni/Classes/Semester7/Stat348/Stat348/projects/AmazonEmployee")
amazontrain <- vroom("./train.csv")
amazontest <- vroom("./test.csv")
amazontrain <- amazontrain %>%
mutate(ACTION = as.factor(ACTION))
#Should have 112 columns
library(tidymodels)
library(embed)
my_recipe <- recipe(ACTION ~ ., data=amazontrain) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod <- logistic_reg(mixture=, penalty=) %>% #Type of model
set_engine("glmnet")
amazon_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = L) ## L^2 total tuning possibilities13
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities13
## Split data for CV15
folds <- vfold_cv(myDataSet, v = 10, repeats=1)
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 10, repeats=1)
## Run the CV
CV_results <- amazon_workflow %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc, f_meas, sens, recall, spec,
precision, accuracy)) #Or leave metrics NULL
## Run the CV
CV_results <- amazon_workflow %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(f_meas, sens, recall, spec,
precision, accuracy)) #Or leave metrics NULL
## Run the CV
CV_results <- amazon_workflow %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(f_meas, sens, recall,
precision, accuracy)) #Or leave metrics NULL
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod <- logistic_reg(mixture=tune(), penalty=tune()) %>% #Type of model
set_engine("glmnet")
## Run the CV
CV_results <- amazon_workflow %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(f_meas, sens, recall,
precision, accuracy)) #Or leave metrics NULL
## Run the CV
CV_results <- amazon_workflow %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=NULL) #Or leave metrics NULL
amazon_workflow_PLR <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod)
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=tune(), penalty=tune()) %>% #Type of model
set_engine("glmnet")
amazon_workflow_PLR <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod_PLR)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities13
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 10, repeats=1)
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=NULL) #Or leave metrics NULL
intall.packages("lme4")
install.packages("lme4")
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=NULL) #Or leave metrics NULL
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=roc_auc) #Or leave metrics NULL
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics="roc_auc") #Or leave metrics NULL
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=, penalty= %>% #Type of model
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=, penalty=) %>% #Type of model
set_engine("glmnet")
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=tune(), penalty=tune()) %>% #Type of model
set_engine("glmnet")
amazon_workflow_PLR <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod_PLR)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities13
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 5, repeats=1)
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(roc_auc)
CV_results
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(roc_auc)
final_wf <- amazon_workflow_PLR %>%
finalize_workflow(bestTune) %>%
fit(data=amazontrain)
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(roc_auc)
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 5, repeats=1)
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(roc_auc)
folds
tuning_grid
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc, precision)) #Or leave metrics NULL
my_recipe <- recipe(ACTION ~ ., data=amazontrain) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
prep <- prep(my_recipe)
my_recipe <- recipe(ACTION ~ ., data=amazontrain) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .01) %>%
step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
my_recipe
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=tune(), penalty=tune()) %>% #Type of model
set_engine("glmnet")
amazon_workflow_PLR <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod_PLR)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 5, repeats=1)
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc, precision)) #Or leave metrics NULL
bestTune
CV_results
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(roc_auc)
library("glmnet")
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=tune(), penalty=tune()) %>% #Type of model
set_engine("glmnet")
my_mod_PLR
amazon_workflow_PLR <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod_PLR)
amazon_workflow_PLR
my_recipe <- recipe(ACTION ~ ., data=amazontrain) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .01) %>%
#step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=tune(), penalty=tune()) %>% #Type of model
set_engine("glmnet")
amazon_workflow_PLR <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod_PLR)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 5, repeats=1)
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc, precision)) #Or leave metrics NULL
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(roc_auc)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 5, repeats=1)
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc, precision)) #Or leave metrics NULL
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(precision)
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(precision)
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best(precision)
amazontrain <- vroom("./train.csv")
amazontest <- vroom("./test.csv")
amazontrain <- amazontrain %>%
mutate(ACTION = as.factor(ACTION))
amazontrain
amazontrain <- vroom("./train.csv")
amazontest <- vroom("./test.csv")
my_recipe <- recipe(ACTION ~ ., data=amazontrain) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .01) %>%
#step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=tune(), penalty=tune()) %>% #Type of model
set_engine("glmnet")
amazon_workflow_PLR <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod_PLR)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 5, repeats=1)
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
amazontrain <- amazontrain %>%
mutate(ACTION = as.factor(ACTION))
my_recipe <- recipe(ACTION ~ ., data=amazontrain) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
step_other(all_nominal_predictors(), threshold = .01) %>%
#step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
my_recipe <- recipe(ACTION ~ ., data=amazontrain) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .01) %>%
#step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
my_recipe
prep <- prep(my_recipe)
baked <- bake(prep, new_data = amazontrain)
library(tidyverse)
library(tidymodels)
library(vroom)
library(embed)
amazontrain <- vroom("./train.csv")
amazontest <- vroom("./test.csv")
amazontrain
amazontest
amazontrain <- amazontrain %>%
mutate(ACTION = as.factor(ACTION))
#Should have 112 columns
library(tidymodels)
library(embed)
my_recipe <- recipe(ACTION ~ ., data=amazontrain) %>%
step_mutate_at(all_numeric_predictors(), fn = factor) %>%
#step_other(all_nominal_predictors(), threshold = .01) %>%
#step_dummy(all_nominal_predictors()) %>%
step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
my_mod <- logistic_reg() %>% #Type of model
set_engine("glm")
amazon_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod) %>%
fit(data = amazontrain) # Fit the workflow
amazon_predictions <- predict(amazon_workflow,
new_data=amazontest,
type="prob") # "class" or "prob" (see doc)
amazon_predictions
#############################################################
#Penalized Logistic Regression
#############################################################
my_mod_PLR <- logistic_reg(mixture=tune(), penalty=tune()) %>% #Type of model
set_engine("glmnet")
amazon_workflow_PLR <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_mod_PLR)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV15
folds <- vfold_cv(amazontrain, v = 5, repeats=1)
## Run the CV
CV_results <- amazon_workflow_PLR %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(roc_auc)) #Or leave metrics NULL
CV_results
#Find the best tuning parameters
bestTune <- CV_results %>%
select_best('roc_auc')
final_wf <- amazon_workflow_PLR %>%
finalize_workflow(bestTune) %>%
fit(data=amazontrain)
final_wf %>% predict(new_data = amazontest, type="prob")
amazon_predictions_PLR <- final_wf %>% predict(new_data = amazontest, type="prob")
submission <- amazon_predictions_PLR %>%
mutate(id = amazontest$id) %>%
mutate(Action = .pred_1) %>%
select(3, 4)
vroom_write(submission, "amazonlogpr.csv", delim = ",")
bestTune
